# Final_Project_NihitaGuda

We created our project on Jupiter Notebook, and along with the importation of libraries and modules, we were able to recognize and graph visual representations of the types of gender biases in various imputed articles and texts. Originally, we had planned to use Word2Vec, creating analogies to identify words associated with pronouns. However, we found this to be a challenge as we did not have enough trainable data to "train" the model to identify patterns in the text. To overcome this difficulty, we attempted to code a similar process to what the model uses. The code identified the gender-related pronouns in each sentence and then looked for specific words that had already been defined in the code. We also found it challenging to insert the LIWC dataset into our code. The dataset was meant to be used to identify words that fall into already established categories, which would allow our program to categorize the words associated with the male and female genders. We found this to be an issue as the dataset was not in an accessible text format (which we had not anticipated beforehand). We overcame this issue by creating lists that included words from each necessary category. We believe that this project helped us understand that there is no right way to code. There may be an easier and harder way to code, but there are many paths that can be taken to get the same results. Although it took a lot of research and experimentation to figure out how exactly to utilize certain modules, we were able to gain more understanding in the process of how these models work. Understanding that allowed us to have more fun with the code because we were able to experiment with different ways that we could get the output that we wanted. Although we used a small example input of text, we believe this can be effective in a much larger scale as well and could be an important tool going forward. 
